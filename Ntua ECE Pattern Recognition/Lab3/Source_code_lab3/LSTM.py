# -*- coding: utf-8 -*-
"""regressionteliko.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MjHYxLCgM_EvMYfn-J_Z57lGs0ThLaaE
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
       # print(os.path.join(dirname, filename))
       i=0
# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

os.listdir('/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/')

with open("/kaggle/input/patreco3-multitask-affective-music/data/multitask_dataset/train_labels.txt") as f:
    lines=f.readlines()
print(lines[1])
print(lines[1].strip().split(','))

import copy
import os

import numpy as np
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler





def torch_train_val_test_split(
    dataset, batch_train, batch_eval, val_size=0.2,test_size=0.15 ,shuffle=True, seed=420
):
    # Creating data indices for training and validation splits:
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    val_split = int(np.floor(val_size * dataset_size))
    test_split = int(np.floor(test_size * dataset_size))
    if shuffle:
        np.random.seed(seed)
        np.random.shuffle(indices)
    train_indices = indices[val_split+test_split:]
    val_indices = indices[:val_split]
    test_indices = indices[val_split:test_split+val_split]

    # Creating PT data samplers and loaders:
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)
    test_sampler=SubsetRandomSampler(test_indices)

    train_loader = DataLoader(dataset, batch_size=batch_train, sampler=train_sampler)
    val_loader = DataLoader(dataset, batch_size=batch_eval, sampler=val_sampler)
    test_loader=DataLoader(dataset, batch_size=32, sampler=test_sampler)
    return train_loader, val_loader,test_loader


def read_multi(spectrogram_file):
    '''
        spectrogram_file:  String, path file
    '''
    spectrogram = np.load(spectrogram_file)[0:128]
    return spectrogram.T

class PaddingTransform(object):
    def __init__(self, max_length, padding_value=0):
        self.max_length = max_length
        self.padding_value = padding_value

    def __call__(self, s):
        if len(s) == self.max_length:
            return s

        if len(s) > self.max_length:
            return s[: self.max_length]

        if len(s) < self.max_length:
            s1 = copy.deepcopy(s)
            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)
            s1 = np.vstack((s1, pad))
            return s1


class SpectrogramDataset(Dataset):
    def __init__(self, path, train=True, max_length=-1,regression=None,read_value=read_multi,kind=-1
    ):
        t= 'train' if train else 'test'
        p = os.path.join(path, t)
        self.index = os.path.join(path, "{}_labels.txt".format(t))
        self.files, labels = self.get_files_labels(self.index, kind)
        self.feats = [read_value(os.path.join(p, f)) for f in self.files]
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        if isinstance(labels, (list, tuple)):
            self.labels = np.array(labels).astype('float')
            
    def get_files_labels(self, txt, kind):
        # Returns a list of file names and a list of their labels
        with open(txt, 'r') as fd:
            lines = [l.rstrip().split(',') for l in fd.readlines()[1:]]
            
        files, labels = [], []
        for l in lines:
            label = l[kind+1]
            labels.append(label)
            # Kaggle automatically unzips the npy.gz format so this hack is needed
            _id = int(l[0])
            npy_file = '{}.fused.full.npy'.format(_id)
            files.append(npy_file)
        return files, labels

    def __getitem__(self, item):
        length = min(self.lengths[item], self.max_length)
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length

    def __len__(self):
        return len(self.labels)

"""Building datasets"""
if __name__ == "__main__":
    """VALENCE"""
    
    # Dataset
    multi_dataset_0 = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/multitask_dataset/', train=True,
                                          max_length=-1,
                                         read_value=read_multi,kind=0)
    # Train,Validation and Test loaders
    train_loader_multi_0, val_loader_multi_0,test_loader_multi_0 = torch_train_val_test_split(multi_dataset_0, batch_train=32,batch_eval= 32, val_size=.15,test_size=0.15)

    """ENERGY"""
    # Dataset
    multi_dataset_1 = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/multitask_dataset/', train=True,
                                         max_length=-1,
                                         read_value=read_multi,kind=1)
    # Train,Validation and Test loaders
    train_loader_multi_1, val_loader_multi_1,test_loader_multi_1 = torch_train_val_test_split(multi_dataset_1, batch_train=32,batch_eval= 32, val_size=.15,test_size=0.15)
    
    """DANCEABILITY"""
    
    # Dataset
    multi_dataset_2 = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/multitask_dataset/', train=True,
                                          max_length=-1,
                                         read_value=read_multi,kind=2)
    # Train,Validation and Test loaders
    train_loader_multi_2, val_loader_multi_2,test_loader_multi_2 = torch_train_val_test_split(multi_dataset_2, batch_train=32,batch_eval= 32, val_size=.15,test_size=0.15)

import torch
import pickle
from torch.utils.data import Dataset
import torch.nn as nn
import warnings
warnings.filterwarnings("ignore")
from sklearn.metrics import classification_report
from scipy import stats
import matplotlib.pyplot as plt
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class BasicLSTM(nn.Module):
    nn.Dropout(0.15)
    def __init__(self, input_dim, rnn_size, output_dim, num_layers, bidirectional=False):
        super(BasicLSTM, self).__init__()
        self.bidirectional = bidirectional
        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size
        self.rnnsize = rnn_size
        self.nl = num_layers
        self.lstm = nn.LSTM(input_dim, rnn_size, num_layers, batch_first=True, bidirectional=bidirectional)
        self.fc = nn.Linear(self.feature_size, output_dim)  

        # --------------- Insert your code here ---------------- #
        # Initialize the LSTM, Dropout, Output layers


    def forward(self, x, lengths):
        """ 
            x : 3D numpy array of dimension N x L x D
                N: batch index
                L: sequence index
                D: feature index
            lengths: N x 1
         """
        isbidirectional = 1
        x = x.float()
        # --------------- Insert your code here ---------------- #
        if self.bidirectional:
            isbidirectional = 2  
        h0 = torch.zeros(self.nl*isbidirectional, x.size(0), self.rnnsize).to(device) 
        c0 = torch.zeros(self.nl*isbidirectional, x.size(0), self.rnnsize).to(device)
        outputs, _ = self.lstm(x, (h0, c0)) 
     
        outputs = self.fc(outputs[:, :, :])
        last_outputs = self.last_timestep(outputs, lengths, bidirectional=self.bidirectional)

        # You must have all of the outputs of the LSTM, but you need only the last one (that does not exceed the sequence length)
        # To get it use the last_timestep method
        # Then pass it through the remaining network

        return last_outputs

    def last_timestep(self, outputs, lengths, bidirectional=False):
        """
            Returns the last output of the LSTM taking into account the zero padding
        """
        if bidirectional:
            forward, backward = self.split_directions(outputs)
            last_forward = self.last_by_index(forward, lengths)
            last_backward = backward[:, 0, :]
            # Concatenate and return - maybe add more functionalities like average
            return torch.cat((last_forward, last_backward), dim=-1)

        else:
            return self.last_by_index(outputs, lengths)

    @staticmethod
    def split_directions(outputs):
        direction_size = int(outputs.size(-1) / 2)
        forward = outputs[:, :, :direction_size]
        backward = outputs[:, :, direction_size:]
        return forward, backward

    @staticmethod
    def last_by_index(outputs, lengths):
        # Index of the last output for each sequence.
        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),
                                               outputs.size(2)).unsqueeze(1)
        return outputs.gather(1, idx).squeeze()

    
    
def training_LSTM(trainloader,valloader,model_name,input_size,dataset,kind):
    model_name+= ".sav"
    
    #defining the device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    #defining the hyperparameters and the  model
    
    rnn_size = 100
    num_layers = 2
    num_classes = 1
    num_epochs = 50
    learning_rate = 0.001
    bidirectional = True

    maxseqlen = dataset.max_length
    model = BasicLSTM(input_size, rnn_size, num_classes, num_layers, bidirectional=bidirectional).to(device)
    model = model.float()
    
    #loss_criterion and optimizer
    criterion = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
    ts = len(trainloader)
    
    v_loss=[]
    t_loss=[]
    train_loss=[]
  
    for epoch in range(num_epochs):# loop over the dataset multiple times 
        with torch.no_grad():
            
            val_loss = 0.0
            best_val_loss = 1000000000
            total=0
            correct=0
            for i, (feats,labels,lengths) in enumerate(valloader):
                # get the inputs; data is a list of [inputs, labels]
                #inputs, labels = data
                #feats = feats.cuda() 
                feats=feats.to(device)
                labels = labels.to(device) 
                lengths = lengths.to(device) 

                # forward + validation_loss
                outputs = model(feats, lengths)
                #print(outputs.shape)
                loss = criterion(outputs, labels).float()
                val_loss+= loss.item()

                #checking the performance of the validation set at the end of each epoch
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
            #if epoch>=1:
             #   print('Validation Accuracy after the end of the nu'+str(epoch)+' epoch= {} %'.format(100 * correct / total))
        
        v_loss.append(val_loss/len(valloader))
        
        if val_loss<=best_val_loss:
            best_val_loss = val_loss
            pickle.dump(model, open(model_name, 'wb'))
        
        
        running_loss=0.0
        train_loss.append([])
        for i,(feats, labels, lengths) in enumerate(trainloader):
            feats = feats.reshape(-1, maxseqlen, input_size).to(device)
            labels=labels.to(device)
            labels = labels.float()
            lengths = lengths.to(device)

            #Forward_pass,Backward,Optimize
            outputs = model(feats, lengths).float()
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if (i) % 8 == 0:
                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                       .format(epoch+1, num_epochs, i+1, ts, loss.item()))
            train_loss[epoch].append(loss.item())

            # epoch loss
            running_loss += loss
            running_loss = running_loss / len(trainloader)

        t_loss.append(np.mean(train_loss))
    
    
    # Tranform losses to numpy arrays
    t_loss=np.array(t_loss)
    v_loss=np.array(v_loss)
    types=['valence ', 'energy', 'danceability']    
    # Plotting learning curve
    plt.figure()
    plt.plot(t_loss, label="training loss")
    plt.plot(v_loss, label="validation loss")
    plt.xlabel('epoch')
    plt.ylabel('mean loss in the epoch')
    plt.title(types[kind])
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
    plt.show()
    
    return maxseqlen
            
            
            
            
            




def score_LSTM(test_loader,input_size,model_name,kind):
    # Estimating the model with classification report
    model_name += ".sav"
    types=['valence ', 'energy', 'danceability'] 
    loaded_model = pickle.load(open(model_name, 'rb'))
    maxseqlen=test_loader.dataset.max_length
    with torch.no_grad():
        y_pred = []
        y_true = []
        total=0
        correct=0
        for i,(feats, labels, lengths) in enumerate(test_loader):
            feats_test = feats.reshape(-1, maxseqlen, input_size).to(device)
            labels = labels.to(device)
            labels = labels.float()
            lengths = lengths.to(device)
            outputs2 = loaded_model(feats_test, lengths).float()
            for pred in outputs2:
                y_pred.append(pred.item()) 
            for label in labels:
                y_true.append(label.item())

    #PLOT
    plt.plot(y_true, y_pred, 'o', color='blue'); 
    plt.title(types[kind])
    plt.xlabel("Y_true")
    plt.ylabel("Y_pred")
           
       
    return stats.spearmanr(y_pred, y_true)[0]

"""Regression_Lstm for the feeling of **Valence**"""

maxseqlen = training_LSTM(train_loader_multi_0, val_loader_multi_0, "LSTM_multi0", input_size=128, dataset=multi_dataset_0, kind=0)
score_lstm_multi0=score_LSTM(test_loader=test_loader_multi_0, model_name="LSTM_multi0", input_size=128,  kind=0)
print(score_lstm_multi0)

"""Regression_Lstm for the feeling of **Energy**"""

maxseqlen = training_LSTM(train_loader_multi_1, val_loader_multi_1, "LSTM_multi1", input_size=128, dataset=multi_dataset_1, kind=1)
score_lstm_multi1=score_LSTM(test_loader=test_loader_multi_1, model_name="LSTM_multi1", input_size=128,  kind=1)
print(score_lstm_multi1)

"""Regression_Lstm for the feeling of **DanceAbility**"""

maxseqlen = training_LSTM(train_loader_multi_2, val_loader_multi_2, "LSTM_multi2", input_size=128, dataset=multi_dataset_2, kind=2)
score_lstm_multi2=score_LSTM(test_loader=test_loader_multi_2, model_name="LSTM_multi2", input_size=128,  kind=2)
print(score_lstm_multi2)

import torch
import pickle
from torch.utils.data import Dataset
import torch.nn as nn
import warnings
warnings.filterwarnings("ignore")
import torch.nn.functional as F
from torch.autograd import Variable
import matplotlib.pyplot as plt
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
from sklearn.metrics import classification_report
class CNN(nn.Module):

    def __init__(self):
    
        super(CNN, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 4, kernel_size=3),
            nn.BatchNorm2d(4),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )    
        self.layer2 = nn.Sequential(
            nn.Conv2d(4, 32, kernel_size=5),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)    
            )
        self.layer3 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=5),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )
        self.layer4 = nn.Sequential(
            nn.Conv2d(64,128, kernel_size=3),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )
        
        self.fc1 = nn.Linear(49920, 1)
        
        
        
        
    def forward(self, x):
        # Forward function of CNN
        
        out = self.layer1(x)     # conv1
        out = self.layer2(out)   # conv2
        out = self.layer3(out)   # conv3
        out = self.layer4(out)   # conv4
        out = out.view(out.size(0), -1)
        out = self.fc1(out)      # fully-connected1
        return out
    
def training_CNN(trainloader,valloader,model_name,input_size,dataset,kind):
    model_name+= ".sav"
    
    
    #defining the device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    #defining the hyperparameters and the  model
    maxseqlen = -1
    num_classes = 1
    num_epochs = 30
    learning_rate = 0.00005
    lamda2=10
    types=['valence ', 'energy', 'danceability']
    

    maxseqlen = dataset.max_length
    model = CNN().to(device)
    model = model.double()
    
    #loss_criterion and optimizer
    criterion = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
    ts = len(trainloader)
    
    v_loss=[]
    t_loss=[]
    train_loss=[]
  
    for epoch in range(num_epochs):# loop over the dataset multiple times 
        with torch.no_grad():
            
            val_loss = 0.0
            best_val_loss = 1000000000
            total=0
            correct=0
            for i, (feats,labels,lengths) in enumerate(valloader):

                feats_val = feats.reshape(-1,1, maxseqlen, input_size).to(device)
                labels = labels.to(device)
                labels=labels.float()
                lengths = lengths.to(device) 

                # forward + validation_loss
                outputs = model.forward(feats_val).float()
                weights = torch.cat([x.view(-1) for x in model.fc1.parameters()])
                l2_regularization = lamda2 *torch.norm(weights, 2)
                loss = criterion(outputs, labels)+l2_regularization
                val_loss+= loss.item() 

                #checking the performance of the validation set at the end of each epoch
                _, predicted = torch.max(outputs.data, -1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
            #if epoch>=1:
             #   print('Validation Accuracy after the end of the nu'+str(epoch)+' epoch= {} %'.format(100 * correct / total))
        
        v_loss.append(val_loss/len(valloader))
        
        if val_loss<=best_val_loss:
            best_val_loss = val_loss
            pickle.dump(model, open(model_name, 'wb'))
        
        
        running_loss=0.0
        train_loss.append([])
        for i,(feats, labels, lengths) in enumerate(trainloader):
            feats = feats.reshape(-1, 1,maxseqlen, input_size).to(device)
            labels = labels.to(device)
            labels=labels.float()
            lengths = lengths.to(device)
            
            #Forward_pass,Backward,Optimize
            outputs = model.forward(feats).float()
            weights = model.fc1.parameters
            weights=np.array(weights)
            
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            if (i) % 8 == 0:
                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                       .format(epoch+1, num_epochs, i+1, ts, loss.item()))
            train_loss[epoch].append(loss.item())
            
            # epoch loss
            running_loss += loss
            running_loss = running_loss / len(trainloader)
          
        t_loss.append(np.mean(train_loss))
    
    
    # Tranform losses to numpy arrays
    t_loss=np.array(t_loss)
    v_loss=np.array(v_loss)
        
    # Plotting learning curve
    plt.figure()
    plt.plot(t_loss, label="training loss")
    plt.plot(v_loss, label="validation loss")
    plt.xlabel('epoch')
    plt.ylabel('mean loss in the epoch')
    plt.title(types[kind])
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
    plt.show()
    
    return maxseqlen
            
            
            
            
            




def score_CNN(test_loader,input_size,model_name,kind):
    # Estimating the model with classification report
    model_name += ".sav"
    loaded_model = pickle.load(open(model_name, 'rb'))
    maxseqlen=test_loader.dataset.max_length
    types=['valence ', 'energy', 'danceability']
    
    # Disable batch normalization and dropout in testing
    loaded_model.eval()
    
    with torch.no_grad():
        correct = 0
        total = 0
        y_pred = []
        y_true = []
        for i,(feats, labels, lengths) in enumerate(test_loader):
            feats_test = feats.reshape(-1,1, maxseqlen, input_size).to(device)
            labels = labels.to(device)
            labels = labels.float()
            lengths = lengths.to(device)
            outputs2 = loaded_model.forward(feats_test).float()
            for pred in outputs2:
                   y_pred.append(pred.item())
            for label in labels:
                  y_true.append(label.item())
    #PLOT
    plt.plot(y_true, y_pred, 'o', color='blue'); 
    plt.title(types[kind])
    plt.xlabel("Y_true")
    plt.ylabel("Y_pred")
           
       
    return stats.spearmanr(y_pred, y_true)[0]

print(dir(nn.Linear))

training_CNN(train_loader_multi_0, val_loader_multi_0, "CNN_multi0", input_size=128, dataset=multi_dataset_0, kind=0)
score_cnn_multi0=score_CNN(test_loader=test_loader_multi_0, model_name="CNN_multi0", input_size=128,  kind=0)
print(score_cnn_multi0)

training_CNN(train_loader_multi_0, val_loader_multi_0, "CNN_multi0", input_size=128, dataset=multi_dataset_0, kind=1)
score_cnn_multi0=score_CNN(test_loader=test_loader_multi_0, model_name="CNN_multi0", input_size=128,  kind=0)
print(score_cnn_multi0)

training_CNN(train_loader_multi_0, val_loader_multi_0, "CNN_multi0", input_size=128, dataset=multi_dataset_0, kind=2)
score_cnn_multi0=score_CNN(test_loader=test_loader_multi_0, model_name="CNN_multi0", input_size=128,  kind=0)
print(score_cnn_multi0)