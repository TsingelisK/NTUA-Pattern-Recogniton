# -*- coding: utf-8 -*-
"""mexrier5teliko.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/143n0rrzAymgl1MfyIPi2NZY41_WR75Kx
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
   #     print(os.path.join(dirname, filename))
      i=0
# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

os.listdir("/kaggle/input/patreco3-multitask-affective-music/data")

os.listdir("/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms")

with open('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train_labels.txt', 'r') as f:
    lines=f.readlines()
    info=[]
    for line in lines:
        genre=line.split()
        ID=genre[0].split('.')
        info.append((ID[0],genre[1]))
print(info)

    


#spec=np.load("/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train_labels.txt")
#os.listdir("/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train_labels")

import random
choice=random.sample(info,2)
if choice[0][1]==choice[1][1]:
    print('make another choice')

spec1 = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/' +str(choice[0][0]) + '.fused.full.npy')
spec2 = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/' +str(choice[1][0]) + '.fused.full.npy')
"""The shape is (mel + chroma frequencies, timesteps)"""

print('the shape of the fist sample is:',spec1.shape)
print('the shape of the secondsample is:',spec2.shape)
print('The shape is (mel + chroma frequencies, timesteps)')

"""decompose into the mel spectrogram and chromagram"""
mel1, chroma1 = spec1[:128], spec1[128:]
mel2, chroma2 = spec2[:128], spec2[128:]
print(mel1.shape,mel2.shape)
print(chroma1.shape,chroma2.shape)

"""plot the specogram for the two different labels"""
import librosa.display
import matplotlib.pyplot as plt

fig1, ax1 = plt.subplots()
img = librosa.display.specshow(mel1, x_axis='time', y_axis='linear', ax=ax1)
ax1.set(title='Mel_Spectrogram for the file with genre:' +str(choice[0][1]) + ' and ID:' +str(choice[0][0]))
fig1.colorbar(img, ax=ax1, format="%+2.f dB")


fig2, ax2 = plt.subplots()
img = librosa.display.specshow(mel2, y_axis='linear', x_axis='time', ax=ax2)
ax2.set(title='Mel_Spectrogram for the file with genre:' +str(choice[1][1]) + ' and ID:' +str(choice[1][0]))
fig2.colorbar(img, ax=ax2,format="%+2.f dB")

info=np.asarray(info)
labels=np.unique(info[1:,1])
print(labels)
print(len(labels))
"""παίρνουμε ένα τυχαίο δείγμα για κάθε label"""
array=[]
for label in labels:
    for idx in range(info.shape[0]):
        if info[idx,1]==label:
            array.append(info[idx])
            break
print(array)            
print(len(array))
print(array[0][0])

"""οπτικοποιώ το mel_spectogram για κάθε ένα απο τα αρχεία των διαφορετικών labels που διαχώρισα παραπάνω"""
for i in range(len(array)):
    file=array[i]
    spec = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/' +str(file[0]) + '.fused.full.npy')
    mel=spec[:128]
    fig, ax = plt.subplots()
    img = librosa.display.specshow(mel, x_axis='time', y_axis='linear', ax=ax)
    ax.set(title='Mel_Spectrogram for the file with genre:' +str(file[1] +' and ID:' + str(file[0])))
    fig.colorbar(img, ax=ax, format="%+2.f dB")

"""κάνουμε load τα beat των 2 αρχείων που επιλέξαμε αρχικά στο βήμα 1"""
beat1= np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/' +str(choice[0][0]) + '.fused.full.npy')
beat2= np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/' +str(choice[1][0]) + '.fused.full.npy')

print('the shape of the first beat_sync sample is :',beat1.shape)
print('the shape of the second beat_sync sample is :',beat2.shape)

mel_beat1=beat1[:128]
mel_beat2=beat2[:128]

fig, ax = plt.subplots(2,2,figsize=(15,13))
img = librosa.display.specshow(mel_beat1, x_axis='time', y_axis='linear', ax=ax[0,0])
ax[0,0].set(title='Beat_Spectrogram for the file with genre:' +str(choice[0][1]) +' and ID:' + str(choice[0][0]))
fig.tight_layout(pad=3.0)
fig.colorbar(img, ax=ax[0,0], format="%+2.f dB")
#fig.tight_layout(pad=3.0)

img = librosa.display.specshow(mel_beat2, x_axis='time', y_axis='linear', ax=ax[1,0])
ax[1,0].set(title='Beat_Spectrogram for the file with genre:' +str(choice[1][1]) +' and ID:' + str(choice[1][0]))
fig.colorbar(img, ax=ax[1,0], format="%+2.f dB")

img = librosa.display.specshow(mel1, x_axis='time', y_axis='linear', ax=ax[0,1])
ax[0,1].set(title='Mel_Spectrogram for the file with genre:' +str(choice[0][1]) + ' and ID:' +str(choice[0][0]))
fig.colorbar(img, ax=ax[0,1], format="%+2.f dB")

img = librosa.display.specshow(mel2, y_axis='linear', x_axis='time', ax=ax[1,1])
ax[1,1].set(title='Mel_Spectrogram for the file with genre:' +str(choice[1][1]) + ' and ID:' +str(choice[1][0]))
fig.colorbar(img, ax=ax[1,1], format="%+2.f dB")

"""εφαρμόζω την ίδια διαδικασία για 1 τυχαίο δείγμα από κάθε label τα οποία ήδη υπάρχουν στον πίνακα array που δημιουργήσαμε προηγουμένως"""
for i in range(len(array)):
    file=array[i]
    spec = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/' +str(file[0]) + '.fused.full.npy')
    spec_beat = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/' +str(file[0]) + '.fused.full.npy')
    mel=spec[:128]
    mel_beat=spec_beat[:128]
    fig, ax = plt.subplots(1,2,figsize=(15,7))
    img = librosa.display.specshow(mel, x_axis='time', y_axis='linear', ax=ax[0])
    ax[0].set(title='Mel_Spectrogram for the file with genre:' +str(file[1] +' and ID:' + str(file[0])))
    fig.tight_layout(pad=3.0)
    fig.colorbar(img, ax=ax[0], format="%+2.f dB")
    
    img = librosa.display.specshow(mel_beat, x_axis='time', y_axis='linear', ax=ax[1])
    ax[1].set(title='Beat_Spectrogram for the file with genre:' +str(file[1] +' and ID:' + str(file[0])))
    fig.colorbar(img, ax=ax[1], format="%+2.f dB")

"""Επαναλαμβάνω το παραπάνω βήμα για το χρωματογραφήματα"""
for i in range(len(array)):
    file=array[i]
    spec = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/train/' +str(file[0]) + '.fused.full.npy')
    spec_beat = np.load('/kaggle/input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train/' +str(file[0]) + '.fused.full.npy')
    chroma=spec[128:]
    chroma_beat=spec_beat[128:]
    fig, ax = plt.subplots(1,2,figsize=(15,7))
    img = librosa.display.specshow(chroma, x_axis='time', y_axis='chroma', ax=ax[0])
    ax[0].set(title='Chromagram for the file with genre:' +str(file[1] +' and ID:' + str(file[0])))
    fig.tight_layout(pad=3.0)
    fig.colorbar(img, ax=ax[0], format="%+2.f dB")
    
    img = librosa.display.specshow(chroma_beat, x_axis='time', y_axis='chroma', ax=ax[1])
    ax[1].set(title='Beat_Chromagram for the file with genre:' +str(file[1] +' and ID:' + str(file[0])))
    fig.colorbar(img, ax=ax[1], format="%+2.f dB")

"""# **BHMA 4**

"""

import copy
import os

import numpy as np
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler

# HINT: Use this class mapping to merge similar classes and ignore classes that do not work very well
Class_Mapping = {
    "Rock": "Rock",
    "Psych-Rock": "Rock",
    "Indie-Rock": None,
    "Post-Rock": "Rock",
    "Psych-Folk": "Folk",
    "Folk": "Folk",
    "Metal": "Metal",
    "Punk": "Metal",
    "Post-Punk": None,
    "Trip-Hop": "Trip-Hop",
    "Pop": "Pop",
    "Electronic": "Electronic",
    "Hip-Hop": "Hip-Hop",
    "Classical": "Classical",
    "Blues": "Blues",
    "Chiptune": "Electronic",
    "Jazz": "Jazz",
    "Soundtrack": None,
    "International": None,
    "Old-Time": None,
}


def torch_train_val_split(
    dataset, batch_train, batch_eval, val_size=0.3, shuffle=True, seed=420
):
    # Creating data indices for training and validation splits:
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    val_split = int(np.floor(val_size * dataset_size))
    if shuffle:
        np.random.seed(seed)
        np.random.shuffle(indices)
    train_indices = indices[val_split:]
    val_indices = indices[:val_split]

    # Creating PT data samplers and loaders:
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)

    train_loader = DataLoader(dataset, batch_size=batch_train, sampler=train_sampler)
    val_loader = DataLoader(dataset, batch_size=batch_eval, sampler=val_sampler)
    return train_loader, val_loader


def read_spectrogram(spectrogram_file):
    # with open(spectrogram_file, "r") as f:
    spectrograms = np.load(spectrogram_file)
    # spectrograms contains a fused mel spectrogram and chromagram
    # Decompose as follows
    return spectrograms.T
def read_mel_spectrogram(spectrogram_file):
    # with open(spectrogram_file, "r") as f:
    spectrograms = np.load(spectrogram_file)
    mel_spectrogram=spectrograms[:128]
    # spectrograms contains a fused mel spectrogram and chromagram
    # Decompose as follows
    return mel_spectrogram.T
def read_chroma_spectrogram(spectrogram_file):
    # with open(spectrogram_file, "r") as f:
    spectrograms = np.load(spectrogram_file)
    chroma_spectrogram=spectrograms[128:]
    # spectrograms contains a fused mel spectrogram and chromagram
    # Decompose as follows
    return chroma_spectrogram.T


class LabelTransformer(LabelEncoder):
    def inverse(self, y):
        try:
            return super(LabelTransformer, self).inverse_transform(y)
        except:
            return super(LabelTransformer, self).inverse_transform([y])

    def transform(self, y):
        try:
            return super(LabelTransformer, self).transform(y)
        except:
            return super(LabelTransformer, self).transform([y])


class PaddingTransform(object):
    def __init__(self, max_length, padding_value=0):
        self.max_length = max_length
        self.padding_value = padding_value

    def __call__(self, s):
        if len(s) == self.max_length:
            return s

        if len(s) > self.max_length:
            return s[: self.max_length]

        if len(s) < self.max_length:
            s1 = copy.deepcopy(s)
            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)
            s1 = np.vstack((s1, pad))
            return s1


class SpectrogramDataset(Dataset):
    def __init__(
        self, path, class_mapping=None, train=True, max_length=-1, regression=None,read_value=read_spectrogram
    ):
        t = "train" if train else "test"
        p = os.path.join(path, t)
        self.regression = regression

        self.index = os.path.join(path, "{}_labels.txt".format(t))
        self.files, labels = self.get_files_labels(self.index, class_mapping)
        self.feats = [read_value(os.path.join(p, f)) for f in self.files]
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        self.label_transformer = LabelTransformer()
        if isinstance(labels, (list, tuple)):
            if not regression:
                self.labels = np.array(
                    self.label_transformer.fit_transform(labels)
                ).astype("int64")
            else:
                self.labels = np.array(labels).astype("float64")
            
    def get_files_labels(self, txt, class_mapping):
        with open(txt, "r") as fd:
            lines = [l.rstrip().split("\t") for l in fd.readlines()[1:]]
        files, labels = [], []
        for l in lines:
            if self.regression:
                l = l[0].split(",")
                files.append(l[0] + ".fused.full.npy")
                labels.append(l[self.regression])
                continue
            label = l[1]
            if class_mapping:
                label = class_mapping[l[1]]
            if not label:
                continue
            fname = l[0]
            if fname.endswith(".gz"):
                fname = ".".join(fname.split(".")[:-1])
            _id=l[0].split('.')[0]
            npy_file='{}.fused.full.npy'.format(_id)
            files.append(npy_file)
            labels.append(label)
        return files, labels

    def __getitem__(self, item):
        length = min(self.lengths[item], self.max_length)
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length

    def __len__(self):
        return len(self.labels)

"""bulding datasets"""
if __name__ == "__main__":
    '''
    # Dataset
    beat_mel_specs = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=True,
                                         class_mapping=Class_Mapping, max_length=-1,
                                         read_value=read_mel_spectrogram)
    # Train and Test loaders
    train_loader_beat_mel, val_loader_beat_mel = torch_train_val_split(beat_mel_specs, 32, 32, val_size=.33)
    test_dataset_beat_mel = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=False,
                                                 class_mapping=Class_Mapping, max_length=-1,
                                                 read_value=read_mel_spectrogram)
    test_loader_beat_mel = DataLoader(test_dataset_beat_mel, batch_size=32)
    
    ##################################################################################
    # load beat synced chroma chromagrams
    ##################################################################################
    beat_chroma = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=True,
                                     class_mapping=Class_Mapping, max_length=-1,
                                     read_value=read_chroma_spectrogram)
    train_loader_beat_chroma, val_loader_beat_chroma = torch_train_val_split(beat_chroma, 32, 32, val_size=.33)
    test_dataset_beat_chroma = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=False,
                                                 class_mapping=Class_Mapping, max_length=-1,
                                                 read_value=read_chroma_spectrogram)
    test_loader_beat_chroma = DataLoader(test_dataset_beat_chroma, batch_size=32)
    '''
     ##################################################################################
    # load beat synced spectograms + chromagrams
    ##################################################################################
    beat_fused = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=True,
                                     class_mapping=Class_Mapping, max_length=-1,
                                     read_value=read_spectrogram)
    train_loader_beat_fused, val_loader_beat_fused = torch_train_val_split(beat_fused, 32, 32, val_size=.33)
    test_dataset_beat_fused = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=False,
                                                 class_mapping=Class_Mapping, max_length=-1,
                                                 read_value=read_spectrogram)
    test_loader_beat_fused = DataLoader(test_dataset_beat_fused, batch_size=32)
    

    ##################################################################################
    # load fused speectrogram + chromagram for the full (non-beat-synced) data
    ##################################################################################
    specs_fused = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=True,
                                     class_mapping=Class_Mapping, max_length=-1,
                                     read_value=read_spectrogram)
    train_loader, val_loader = torch_train_val_split(specs_fused, 32, 32, val_size=.33)
    test_dataset = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=False,
                                     class_mapping=Class_Mapping, max_length=-1,
                                     read_value=read_spectrogram)
    test_loader = DataLoader(test_dataset, batch_size=32)
    
    ##################################################################################
    # load single synced mel spectrograms
    ##################################################################################
    # Dataset
    '''
    mel_specs = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=True,
                                        class_mapping=Class_Mapping, max_length=-1,
                                        read_value=read_mel_spectrogram)
    # Train and Test loaders
    train_loader_mel, val_loader_mel = torch_train_val_split(mel_specs, 32, 32, val_size=.33)
    test_dataset_mel = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=False,
                                            class_mapping=Class_Mapping, max_length=-1,
                                            read_value=read_mel_spectrogram)
    test_loader_mel = DataLoader(test_dataset_mel, batch_size=32)
    ##################################################################################
    # load single synced chroma chromagrams
    ##################################################################################
    # Dataset
    chroma_specs = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=True,
                                        class_mapping=Class_Mapping, max_length=-1,
                                        read_value=read_chroma_spectrogram)
    # Train and Test loaders
    train_loader_chroma, val_loader_chroma = torch_train_val_split(chroma_specs, 32, 32, val_size=.33)
    test_dataset_chroma = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=False,
                                            class_mapping=Class_Mapping, max_length=-1,
                                            read_value=read_chroma_spectrogram)
    test_loader_chroma = DataLoader(test_dataset_chroma, batch_size=32)
    '''

print(len(train_loader_mel))

"""Before"""
from collections import Counter
y_train = []
y_test = []

# Train labels
file1 = open('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/train_labels.txt', 'r') 
Lines = file1.readlines()[1:] 
for line in Lines: 
    label = line.split()[1]
    y_train.append(label)
    
# Test labels
file1 = open('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/test_labels.txt', 'r') 
Lines = file1.readlines()[1:] 
for line in Lines: 
    label = line.split()[1]
    y_test.append(label)

c=Counter(y_train)
print(c)
"""Plot a histogram"""
genre = list(c.keys())
values = list(c.values())
  
fig = plt.figure(figsize = (40,15 ))
 
# creating the bar plot
plt.bar(genre, values, color ='royalblue')
 
plt.xlabel("Labels")
plt.ylabel("No. of samples that belong on each label for the training set")
plt.title("histogram for the labels before their reduction")
plt.show()

c=Counter(y_test)
print(c)
"""Plot a histogram"""
genre = list(c.keys())
values = list(c.values())
  
fig = plt.figure(figsize = (30,10 ))
 
# creating the bar plot
plt.bar(genre, values, color ='royalblue')
 
plt.xlabel("Labels")
plt.ylabel("No. of samples that belong on each label for the test set")
plt.title("histogram for the labels before their reduction")
plt.show()

y_train_after=[]
for label in y_train:
    if Class_Mapping[label] is not None:
        y_train_after.append(Class_Mapping[label])
y_test_after=[]
for label in y_test:
    if Class_Mapping[label] is not None:
        y_test_after.append(Class_Mapping[label])

c=Counter(y_train_after)
print(c)
"""Plot a histogram"""
genre = list(c.keys())
values = list(c.values())
  
fig = plt.figure(figsize = (30,10 ))
 
# creating the bar plot
plt.bar(genre, values, color ='royalblue')
 
plt.xlabel("Labels")
plt.ylabel("No. of samples that belong on each label for the training set")
plt.title("histogram for the labels after their reduction")
plt.show()

c=Counter(y_test_after)
print(c)
"""Plot a histogram"""
genre = list(c.keys())
values = list(c.values())
  
fig = plt.figure(figsize = (30,10 ))
 
# creating the bar plot
plt.bar(genre, values, color ='royalblue')
 
plt.xlabel("Labels")
plt.ylabel("No. of samples that belong on each label for the test set")
plt.title("histogram for the labels after their reduction")
plt.show()

"""# BHMA 5

"""

import torch
import joblib
import pickle
from torch.utils.data import Dataset
import torch.nn as nn
import warnings
warnings.filterwarnings("ignore")
from sklearn.metrics import classification_report
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class BasicLSTM(nn.Module):
    nn.Dropout(0.15)
    def __init__(self, input_dim, rnn_size, output_dim, num_layers, bidirectional=False):
        super(BasicLSTM, self).__init__()
        self.bidirectional = bidirectional
        self.feature_size = rnn_size * 2 if self.bidirectional else rnn_size
        self.rnnsize = rnn_size
        self.nl = num_layers
        self.lstm = nn.LSTM(input_dim, rnn_size, num_layers, batch_first=True, bidirectional=bidirectional)
        self.fc = nn.Linear(self.feature_size, output_dim)  

        # --------------- Insert your code here ---------------- #
        # Initialize the LSTM, Dropout, Output layers


    def forward(self, x, lengths):
        """ 
            x : 3D numpy array of dimension N x L x D
                N: batch index
                L: sequence index
                D: feature index
            lengths: N x 1
         """
        isbidirectional = 1
        x = x.float()
        # --------------- Insert your code here ---------------- #
        if self.bidirectional:
            isbidirectional = 2  
        h0 = torch.zeros(self.nl*isbidirectional, x.size(0), self.rnnsize).to(device) 
        c0 = torch.zeros(self.nl*isbidirectional, x.size(0), self.rnnsize).to(device)
        outputs, _ = self.lstm(x, (h0, c0)) 
     
        outputs = self.fc(outputs[:, :, :])
        last_outputs = self.last_timestep(outputs, lengths, bidirectional=self.bidirectional)

        # You must have all of the outputs of the LSTM, but you need only the last one (that does not exceed the sequence length)
        # To get it use the last_timestep method
        # Then pass it through the remaining network

        return last_outputs

    def last_timestep(self, outputs, lengths, bidirectional=False):
        """
            Returns the last output of the LSTM taking into account the zero padding
        """
        if bidirectional:
            forward, backward = self.split_directions(outputs)
            last_forward = self.last_by_index(forward, lengths)
            last_backward = backward[:, 0, :]
            # Concatenate and return - maybe add more functionalities like average
            return torch.cat((last_forward, last_backward), dim=-1)

        else:
            return self.last_by_index(outputs, lengths)

    @staticmethod
    def split_directions(outputs):
        direction_size = int(outputs.size(-1) / 2)
        forward = outputs[:, :, :direction_size]
        backward = outputs[:, :, direction_size:]
        return forward, backward

    @staticmethod
    def last_by_index(outputs, lengths):
        # Index of the last output for each sequence.
        idx = (lengths - 1).view(-1, 1).expand(outputs.size(0),
                                               outputs.size(2)).unsqueeze(1)
        return outputs.gather(1, idx).squeeze()

    
    
def training_LSTM(trainloader,valloader,model_name,input_size,dataset,obover):
    
    model_name+= ".sav"
    if obover==True:
        maxseqlen = dataset.max_length
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        #defining mnodel and the hyperparameters
        train_loss=[]
        rnn_size=100
        num_classes=10
        num_layers=4
        bidirectional=True
        num_epochs=200

        model = BasicLSTM(input_size, rnn_size, num_classes, num_layers, bidirectional=bidirectional).to(device)
        model = model.float()


        # Loss and optimizer
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)

        #take only 1 batch & transfer it to GPU
        feats, labels, lengths= next(iter(trainloader))
        feats, lengths, labels= feats.to(device),lengths.to(device),labels.to(device)

        for epoch in range(num_epochs):

            # Forward pass
            outputs = model(feats, lengths)
            loss = criterion(outputs, labels)

            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss.append(round(loss.item(),4))

            #print results
            print('Epoch [{}/{}], Training Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))
        running_loss=np.array(train_loss)
        plt.figure()
        plt.plot(running_loss, label="training loss")
        plt.xlabel('epoch')
        plt.ylabel('mean loss in the epoch')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
        plt.show()
        
    elif obover==False:
        
    #defining the device
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

            #defining the hyperparameters and the  model
            maxseqlen = -1
            rnn_size = 100
            num_layers = 4
            num_classes = 10
            num_epochs = 30
            learning_rate = 0.001
            bidirectional = True

            maxseqlen = dataset.max_length
            model = BasicLSTM(input_size, rnn_size, num_classes, num_layers, bidirectional=bidirectional).to(device)
            model = model.float()

            #loss_criterion and optimizer
            criterion = nn.CrossEntropyLoss()
            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
            ts = len(trainloader)

            v_loss=[]
            t_loss=[]
            train_loss=[]

            for epoch in range(num_epochs):# loop over the dataset multiple times 
                with torch.no_grad():

                    val_loss = 0.0
                    best_val_loss = 1000000000
                    total=0
                    correct=0
                    for i, (feats,labels,lengths) in enumerate(valloader):
                        # get the inputs; data is a list of [inputs, labels]
                        #inputs, labels = data
                        #feats = feats.cuda() 
                        feats_val = feats.reshape(-1, maxseqlen, input_size).to(device)
                        labels = labels.to(device) 
                        labels = torch.tensor(labels, dtype=torch.long, device=device)
                        lengths = lengths.to(device) 

                        # forward + validation_loss
                        outputs = model(feats_val, lengths)
                        criterion = nn.CrossEntropyLoss()
                        loss = criterion(outputs, labels)
                        val_loss+= loss.item()

                        #checking the performance of the validation set at the end of each epoch
                        _, predicted = torch.max(outputs.data, 1)
                        total += labels.size(0)
                        correct += (predicted == labels).sum().item()
                    if epoch>=1:
                        print('Validation Accuracy after the end of the nu'+str(epoch)+' epoch= {} %'.format(100 * correct / total))

                v_loss.append(val_loss/len(valloader))

                if val_loss<=best_val_loss:
                    best_val_loss = val_loss
                    pickle.dump(model, open(model_name, 'wb'))


                running_loss=0.0
                train_loss.append([])
                for i,(feats, labels, lengths) in enumerate(trainloader):
                    feats = feats.reshape(-1, maxseqlen, input_size).to(device)
                    labels = labels.to(device)
                    labels = torch.tensor(labels, dtype=torch.long, device=device)
                    lengths = lengths.to(device)

                    #Forward_pass,Backward,Optimize
                    outputs = model(feats, lengths)
                    loss = criterion(outputs, labels)
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()

                    if (i) % 8 == 0:
                        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                               .format(epoch+1, num_epochs, i+1, ts, loss.item()))
                    train_loss[epoch].append(loss.item())

                    # epoch loss
                    running_loss += loss
                    running_loss = running_loss / len(trainloader)

                t_loss.append(np.mean(train_loss))


            # Tranform losses to numpy arrays
            t_loss=np.array(t_loss)
            v_loss=np.array(v_loss)

            # Plotting learning curve
            plt.figure()
            plt.plot(t_loss, label="training loss")
            plt.plot(v_loss, label="validation loss")
            plt.xlabel('epoch')
            plt.ylabel('mean loss in the epoch')
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
            plt.show()
    
    return maxseqlen
            
            
            
            
            




def score_LSTM(test_loader,input_size,model_name, maxseqlen):
    # Estimating the model with classification report
    model_name += ".sav"
    loaded_model = pickle.load(open(model_name, 'rb'))
    
    with torch.no_grad():
        correct = 0
        total = 0
        y_pred = []
        y_true = []
        for i,(feats, labels, lengths) in enumerate(test_loader):
            #feats_test = feats.reshape(-1, maxseqlen, input_size).to(device)
            print(feats.shape)
            print(lengths.shape)
            feats = feats.to(device)
            labels = labels.to(device)
            labels = torch.tensor(labels, dtype=torch.long, device=device)
            lengths = lengths.to(device)
            outputs2 = loaded_model(feats, lengths).double()
            _, predicted = torch.max(outputs2.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            for pred in predicted:
                   y_pred.append(pred.item())
            for label in labels:
                  y_true.append(label.item())
    print(classification_report(y_true, y_pred))

"""Subset"""
evens = list(range(0, len(mel_specs), 4))
melspec_subset = torch.utils.data.Subset(mel_specs, evens)
train_loader_mel_subset, val_loader_mel_subset = torch_train_val_split(melspec_subset, 32, 32, val_size=.33)

"""# **Φασματογραφήματα από το non_beat_synchronized dataset **

"""

maxseqlen = training_LSTM(train_loader_mel_subset, val_loader_mel_subset, model_name="lstm_single_mel", input_size=128, dataset=mel_specs,obover=False)
score_LSTM(test_loader=test_loader_mel, model_name="lstm_single_mel", input_size=128, maxseqlen=maxseqlen)

maxseqlen = training_LSTM(train_loader_mel_subset, val_loader_mel_subset, model_name="lstm_single_mel", input_size=128, dataset=mel_specs,obover=True)

"""# Φασματογραφήματα από το beat_synchronized dataset"""

maxseqlen = training_LSTM(train_loader_beat_mel, val_loader_beat_mel, model_name="lstm_beat_mel", input_size=128, dataset=beat_mel_specs,obover=False)
score_LSTM(test_loader=test_loader_beat_mel, model_name="lstm_beat_mel", input_size=128, maxseqlen=maxseqlen)

maxseqlen = training_LSTM(train_loader_beat_mel, val_loader_beat_mel, model_name="lstm_beat_mel", input_size=128, dataset=beat_mel_specs,obover=True)

"""# Χρωματογραφήματα από το beat_synchronized dataset"""

maxseqlen = training_LSTM(train_loader_beat_chroma, val_loader_beat_chroma, model_name="lstm_beat_chroma", input_size=12, dataset=beat_chroma,obover=False)
score_LSTM(test_loader=test_loader_beat_chroma, model_name="lstm_beat_chroma", input_size=12, maxseqlen=maxseqlen)

maxseqlen = training_LSTM(train_loader_beat_chroma, val_loader_beat_chroma, model_name="lstm_beat_chroma", input_size=12, dataset=beat_chroma,obover=True)

"""# Χρωματογραφήματα από το non_beat_synchronized dataset"""

maxseqlen = training_LSTM(train_loader_chroma, val_loader_chroma, model_name="lstm_single_chroma", input_size=12, dataset=chroma_specs,obover=False)
score_LSTM(test_loader=test_loader_chroma, model_name="lstm_single_chroma", input_size=12, maxseqlen=maxseqlen)

maxseqlen = training_LSTM(train_loader_chroma, val_loader_chroma, model_name="lstm_single_chroma", input_size=12, dataset=chroma_specs,obover=True)

"""# Ολόληρο dataset (φασματογραφήματα+χρωματογραφήματα) από το non_beat_synchronized dataset"""

"""Subset"""
evens = list(range(0, len(specs_fused), 4))
specs_fused_subset = torch.utils.data.Subset(specs_fused, evens)
train_loader_subset, val_loader_subset = torch_train_val_split(specs_fused_subset, 32, 32, val_size=.33)

maxseqlen = training_LSTM(train_loader_subset, val_loader_subset, model_name="lstm_single_full", input_size=140, dataset=specs_fused,obover=False)
score_LSTM(test_loader=test_loader, model_name="lstm_single_full", input_size=140, maxseqlen=maxseqlen)

maxseqlen = training_LSTM(train_loader_subset, val_loader_subset, model_name="lstm_single_full", input_size=140, dataset=specs_fused,obover=True)

"""# # Ολόληρο dataset (φασματογραφήματα+χρωματογραφήματα) από το beat_synchronized dataset"""

maxseqlen = training_LSTM(train_loader_beat_fused,val_loader_beat_fused, model_name="lstm_beat_full", input_size=140, dataset=beat_fused,obover=False)
score_LSTM(test_loader=test_loader_beat_fused, model_name="lstm_beat_full", input_size=140, maxseqlen=maxseqlen)

maxseqlen = training_LSTM(train_loader_beat_fused,val_loader_beat_fused, model_name="lstm_beat_full", input_size=140, dataset=beat_fused,obover=True)