# -*- coding: utf-8 -*-
"""bhma9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1InXtn3ePJmUp4dHf3NISxSCIEyZioBIB
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
     #   print(os.path.join(dirname, filename))
     I=0
# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import copy
import os

import numpy as np
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler

# HINT: Use this class mapping to merge similar classes and ignore classes that do not work very well
Class_Mapping = {
    "Rock": "Rock",
    "Psych-Rock": "Rock",
    "Indie-Rock": None,
    "Post-Rock": "Rock",
    "Psych-Folk": "Folk",
    "Folk": "Folk",
    "Metal": "Metal",
    "Punk": "Metal",
    "Post-Punk": None,
    "Trip-Hop": "Trip-Hop",
    "Pop": "Pop",
    "Electronic": "Electronic",
    "Hip-Hop": "Hip-Hop",
    "Classical": "Classical",
    "Blues": "Blues",
    "Chiptune": "Electronic",
    "Jazz": "Jazz",
    "Soundtrack": None,
    "International": None,
    "Old-Time": None,
}


def torch_train_val_split(
    dataset, batch_train, batch_eval, val_size=0.3, shuffle=True, seed=420
):
    # Creating data indices for training and validation splits:
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    val_split = int(np.floor(val_size * dataset_size))
    if shuffle:
        np.random.seed(seed)
        np.random.shuffle(indices)
    train_indices = indices[val_split:]
    val_indices = indices[:val_split]

    # Creating PT data samplers and loaders:
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)

    train_loader = DataLoader(dataset, batch_size=batch_train, sampler=train_sampler)
    val_loader = DataLoader(dataset, batch_size=batch_eval, sampler=val_sampler)
    return train_loader, val_loader


def read_spectrogram(spectrogram_file):
    # with open(spectrogram_file, "r") as f:
    spectrograms = np.load(spectrogram_file)
    # spectrograms contains a fused mel spectrogram and chromagram
    # Decompose as follows
    return spectrograms.T
def read_mel_spectrogram(spectrogram_file):
    # with open(spectrogram_file, "r") as f:
    spectrograms = np.load(spectrogram_file)
    mel_spectrogram=spectrograms[:128]
    # spectrograms contains a fused mel spectrogram and chromagram
    # Decompose as follows
    return mel_spectrogram.T
def read_chroma_spectrogram(spectrogram_file):
    # with open(spectrogram_file, "r") as f:
    spectrograms = np.load(spectrogram_file)
    chroma_spectrogram=spectrograms[128:]
    # spectrograms contains a fused mel spectrogram and chromagram
    # Decompose as follows
    return chroma_spectrogram.T


class LabelTransformer(LabelEncoder):
    def inverse(self, y):
        try:
            return super(LabelTransformer, self).inverse_transform(y)
        except:
            return super(LabelTransformer, self).inverse_transform([y])

    def transform(self, y):
        try:
            return super(LabelTransformer, self).transform(y)
        except:
            return super(LabelTransformer, self).transform([y])


class PaddingTransform(object):
    def __init__(self, max_length, padding_value=0):
        self.max_length = max_length
        self.padding_value = padding_value

    def __call__(self, s):
        if len(s) == self.max_length:
            return s

        if len(s) > self.max_length:
            return s[: self.max_length]

        if len(s) < self.max_length:
            s1 = copy.deepcopy(s)
            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)
            s1 = np.vstack((s1, pad))
            return s1


class SpectrogramDataset(Dataset):
    def __init__(
        self, path, class_mapping=None, train=True, max_length=-1, regression=None,read_value=read_spectrogram
    ):
        t = "train" if train else "test"
        p = os.path.join(path, t)
        self.regression = regression

        self.index = os.path.join(path, "{}_labels.txt".format(t))
        self.files, labels = self.get_files_labels(self.index, class_mapping)
        self.feats = [read_value(os.path.join(p, f)) for f in self.files]
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        self.label_transformer = LabelTransformer()
        if isinstance(labels, (list, tuple)):
            if not regression:
                self.labels = np.array(
                    self.label_transformer.fit_transform(labels)
                ).astype("int64")
            else:
                self.labels = np.array(labels).astype("float64")
            
    def get_files_labels(self, txt, class_mapping):
        with open(txt, "r") as fd:
            lines = [l.rstrip().split("\t") for l in fd.readlines()[1:]]
        files, labels = [], []
        for l in lines:
            if self.regression:
                l = l[0].split(",")
                files.append(l[0] + ".fused.full.npy")
                labels.append(l[self.regression])
                continue
            label = l[1]
            if class_mapping:
                label = class_mapping[l[1]]
            if not label:
                continue
            fname = l[0]
            if fname.endswith(".gz"):
                fname = ".".join(fname.split(".")[:-1])
            _id=l[0].split('.')[0]
            npy_file='{}.fused.full.npy'.format(_id)
            files.append(npy_file)
            labels.append(label)
        return files, labels

    def __getitem__(self, item):
        length = min(self.lengths[item], self.max_length)
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item], length

    def __len__(self):
        return len(self.labels)

"""bulding datasets"""
if __name__ == "__main__":
    
    # Dataset
    
    
    ##################################################################################
    # load beat synced chroma chromagrams
    ##################################################################################
    beat_chroma = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=True,
                                     class_mapping=Class_Mapping, max_length=-1,
                                     read_value=read_chroma_spectrogram)
    train_loader_beat_chroma, val_loader_beat_chroma = torch_train_val_split(beat_chroma, 32, 32, val_size=.33)
    test_dataset_beat_chroma = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms_beat/', train=False,
                                                 class_mapping=Class_Mapping, max_length=-1,
                                                 read_value=read_chroma_spectrogram)
    test_loader_beat_chroma = DataLoader(test_dataset_beat_chroma, batch_size=1)

    ##################################################################################
    # load fused speectrogram + chromagram for the full (non-beat-synced) data
    ##################################################################################
    
    # Dataset
    mel_specs = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=True,
                                        class_mapping=Class_Mapping, max_length=-1,
                                        read_value=read_mel_spectrogram)
    # Train and Test loaders
    train_loader_mel, val_loader_mel = torch_train_val_split(mel_specs, 32, 32, val_size=.33)
    test_dataset_mel = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/fma_genre_spectrograms/', train=False,
                                            class_mapping=Class_Mapping, max_length=-1,
                                            read_value=read_mel_spectrogram)
    test_loader_mel = DataLoader(test_dataset_mel, batch_size=1)

import torch
import pickle
from torch.utils.data import Dataset
import torch.nn as nn
import warnings
warnings.filterwarnings("ignore")
import torch.nn.functional as F
from torch.autograd import Variable
import matplotlib.pyplot as plt
device = torch.device('cpu')
from sklearn.metrics import classification_report

import torch
import pickle
from torch.utils.data import Dataset
import torch.nn as nn
import warnings
warnings.filterwarnings("ignore")
import torch.nn.functional as F
from torch.autograd import Variable
import matplotlib.pyplot as plt
device = torch.device('cpu')
from sklearn.metrics import classification_report

class CNN(nn.Module):

    def __init__(self):
    
        super(CNN, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 4, kernel_size=3),
            nn.BatchNorm2d(4),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )    
        self.layer2 = nn.Sequential(
            nn.Conv2d(4, 32, kernel_size=5),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)    
            )
        self.layer3 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=5),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )
        self.layer4 = nn.Sequential(
            nn.Conv2d(64,128, kernel_size=3),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )
        
        self.fc1 = nn.Linear(49920, 10)
        
        
        
        
    def forward(self, x):
        # Forward function of CNN
        
        out = self.layer1(x)     # conv1
        out = self.layer2(out)   # conv2
        out = self.layer3(out)   # conv3
        out = self.layer4(out)   # conv4
        out = out.view(out.size(0), -1)
        out = self.fc1(out)      # fully-connected1
        return out
    
def training_CNN(trainloader,valloader,model_name,input_size,dataset,obover):
    if obover==True:
        maxseqlen = dataset.max_length
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    #defining mnodel and the hyperparameters
        train_loss=[]
        num_classes=10
        num_epochs=200
        maxseqlen=trainloader.dataset.max_length

        model = CNN().to(device)
        model = model.double()


        # Loss and optimizer
        criterion =nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)

        #take only 1 batch & transfer it to GPU
        feats, labels, lengths= next(iter(trainloader))
        feats=feats.reshape(-1,1,maxseqlen,input_size)
        feats, lengths, labels= feats.to(device),lengths.to(device),labels.to(device)

        for epoch in range(num_epochs):

            # Forward pass
            outputs = model.forward(feats)
            loss = criterion(outputs, labels)

            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss.append(round(loss.item(),4))

            #print results
            print('Epoch [{}/{}], Training Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))



        # Plotting learning curve
        running_loss=np.array(train_loss)
        plt.figure()
        plt.plot(running_loss, label="training loss")
        plt.xlabel('epoch')
        plt.ylabel('mean loss in the epoch')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
        plt.show()




    elif obover==False:  
        model_name+= ".sav"

        #defining the device
        device = torch.device('cpu')
      
        #defining the hyperparameters and the  model
        maxseqlen = -1
        num_classes = 10
        num_epochs = 30
        learning_rate = 0.001


        maxseqlen = dataset.max_length
        model = CNN().to(device)
        model = model.double()
        

        #loss_criterion and optimizer
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        ts = len(trainloader)

        v_loss=[]
        t_loss=[]
        train_loss=[]

        for epoch in range(num_epochs):# loop over the dataset multiple times 
            with torch.no_grad():

                val_loss = 0.0
                best_val_loss = 1000000000
                total=0
                correct=0
                for i, (feats,labels,lengths) in enumerate(valloader):

                    feats_val = feats.reshape(-1,1, maxseqlen, input_size).to(device)
                    labels = labels.to(device) 
                    labels = torch.tensor(labels, dtype=torch.long, device=device)
                    lengths = lengths.to(device) 

                    # forward + validation_loss
                    outputs = model.forward(feats_val)
                    criterion = nn.CrossEntropyLoss()
                    loss = criterion(outputs, labels)
                    val_loss+= loss.item()

                    #checking the performance of the validation set at the end of each epoch
                    _, predicted = torch.max(outputs.data, -1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()
                if epoch>=1:
                    print('Validation Accuracy after the end of the nu'+str(epoch)+' epoch= {} %'.format(100 * correct / total))

            v_loss.append(val_loss/len(valloader))

            if val_loss<=best_val_loss:
                best_val_loss = val_loss
                pickle.dump(model, open(model_name, 'wb'))
                torch.save(model.state_dict(),"w8s.pt")


            running_loss=0.0
            train_loss.append([])
            for i,(feats, labels, lengths) in enumerate(trainloader):
                feats = feats.reshape(-1, 1,maxseqlen, input_size).to(device)
                labels = labels.to(device)
                labels = torch.tensor(labels, dtype=torch.long, device=device)
                lengths = lengths.to(device)

                #Forward_pass,Backward,Optimize
                outputs = model.forward(feats)
                loss = criterion(outputs, labels)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                if (i) % 8 == 0:
                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                           .format(epoch+1, num_epochs, i+1, ts, loss.item()))
                train_loss[epoch].append(loss.item())

                # epoch loss
                running_loss += loss
                running_loss = running_loss / len(trainloader)

            t_loss.append(np.mean(train_loss))


        # Tranform losses to numpy arrays
        t_loss=np.array(t_loss)
        v_loss=np.array(v_loss)

        # Plotting learning curve
        plt.figure()
        plt.plot(t_loss, label="training loss")
        plt.plot(v_loss, label="validation loss")
        plt.xlabel('epoch')
        plt.ylabel('mean loss in the epoch')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
        plt.show()
    
    return maxseqlen
            
            
            
            
            




def score_CNN(test_loader,input_size,model_name, maxseqlen):
    # Estimating the model with classification report
    model_name += ".sav"
    loaded_model = pickle.load(open(model_name, 'rb'))
    maxseqlen=test_loader.dataset.max_length
    
    # Disable batch normalization and dropout in testing
    loaded_model.eval()
    
    with torch.no_grad():
        correct = 0
        total = 0
        y_pred = []
        y_true = []
        for i,(feats, labels, lengths) in enumerate(test_loader):
            feats_test = feats.reshape(-1,1, maxseqlen, input_size).to(device)
            labels = labels.to(device)
            labels = torch.tensor(labels, dtype=torch.long, device=device)
            lengths = lengths.to(device)
            outputs2 = loaded_model.forward(feats_test)
            _, predicted = torch.max(outputs2.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            for pred in predicted:
                   y_pred.append(pred.item())
            for label in labels:
                  y_true.append(label.item())
    print(classification_report(y_true, y_pred))

maxseqlen = training_CNN(train_loader_mel, val_loader_mel, model_name="cnn_single_mel2", input_size=128, dataset=mel_specs,obover=True)

maxseqlen = training_CNN(train_loader_mel, val_loader_mel, model_name="cnn_single_mel2", input_size=128, dataset=mel_specs,obover=False)
score_CNN(test_loader=test_loader_mel, model_name="cnn_single_mel2", input_size=128, maxseqlen=maxseqlen)

class CNN2(nn.Module):

    def __init__(self):
    
        super(CNN2, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 4, kernel_size=3),
            nn.BatchNorm2d(4),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )    
        self.layer2 = nn.Sequential(
            nn.Conv2d(4, 32, kernel_size=5),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)    
            )
        self.layer3 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=5),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )
        self.layer4 = nn.Sequential(
            nn.Conv2d(64,128, kernel_size=3),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )
        
        self.fc1 = nn.Linear(49920, 10)
        self.fc2= nn.Linear(10,1)
        
        
        
    def forward(self, x):
        # Forward function of CNN
        
        out = self.layer1(x)     # conv1
        out = self.layer2(out)   # conv2
        out = self.layer3(out)   # conv3
        out = self.layer4(out)   # conv4
        out = out.view(out.size(0), -1)
        out = self.fc1(out)  
        out = self.fc2(out)  
        # fully-connected1
        return out

def transfer(vanilla, path='w8s.pt'):
    # Transfer Learning
    '''
        vanilla:  nn.Module
    '''
    vanilla.load_state_dict(torch.load(path), strict=False)
    return vanilla

def training_CNN2(trainloader,valloader,model_name,input_size,dataset):
        model_name+= ".sav"

        #defining the device
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
      
        #defining the hyperparameters and the  model
        maxseqlen = -1
        num_classes = 10
        num_epochs = 30
        learning_rate = 0.001


        maxseqlen = dataset.max_length
        model = CNN2()
        model= transfer(model)

        model = model.to(device)
        model = model.double()
        

        #loss_criterion and optimizer
        criterion = nn.CrossEntropy()
        optimizer = torch.optim.SGD(model.parameters(), lr=0.001)
        ts = len(trainloader)

        v_loss=[]
        t_loss=[]
        train_loss=[]

        for epoch in range(num_epochs):# loop over the dataset multiple times 
            with torch.no_grad():

                val_loss = 0.0
                best_val_loss = 1000000000
                total=0
                correct=0
                for i, (feats,labels,lengths) in enumerate(valloader):

                    feats_val = feats.reshape(-1,1, maxseqlen, input_size).to(device)
                    labels = labels.to(device) 
                    labels = torch.tensor(labels, dtype=torch.long, device=device)
                    lengths = lengths.to(device) 

                    # forward + validation_loss
                    outputs = model.forward(feats_val)
                    criterion = nn.CrossEntropy()
                    loss = criterion(outputs, labels)
                    val_loss+= loss.item()

                    #checking the performance of the validation set at the end of each epoch
                    _, predicted = torch.max(outputs.data, -1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()
                if epoch>=1:
                    print('Validation Accuracy after the end of the nu'+str(epoch)+' epoch= {} %'.format(100 * correct / total))

            v_loss.append(val_loss/len(valloader))

            if val_loss<=best_val_loss:
                best_val_loss = val_loss
                pickle.dump(model, open(model_name, 'wb'))
                torch.save(model.state_dict(),"w8s.pt")


            running_loss=0.0
            train_loss.append([])
            for i,(feats, labels, lengths) in enumerate(trainloader):
                feats = feats.reshape(-1, 1,maxseqlen, input_size).to(device)
                labels = labels.to(device)
                labels = torch.tensor(labels, dtype=torch.long, device=device)
                lengths = lengths.to(device)

                #Forward_pass,Backward,Optimize
                outputs = model.forward(feats)
                loss = criterion(outputs, labels)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                if (i) % 8 == 0:
                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                           .format(epoch+1, num_epochs, i+1, ts, loss.item()))
                train_loss[epoch].append(loss.item())

                # epoch loss
                running_loss += loss
                running_loss = running_loss / len(trainloader)

            t_loss.append(np.mean(train_loss))


        # Tranform losses to numpy arrays
        t_loss=np.array(t_loss)
        v_loss=np.array(v_loss)

        # Plotting learning curve
        plt.figure()
        plt.plot(t_loss, label="training loss")
        plt.plot(v_loss, label="validation loss")
        plt.xlabel('epoch')
        plt.ylabel('mean loss in the epoch')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
        plt.show()
    
        return maxseqlen

!ls

maxseqlen = training_CNN2(train_loader_mel, val_loader_mel, model_name="cnn_single_mel2", input_size=128, dataset=mel_specs)

import numpy as np
import copy
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import Dataset
from torch.utils.data import SubsetRandomSampler, DataLoader
import re

def torch_train_val_test_split(dataset, batch_train, batch_eval,kind,
                            val_size=.10, test_size=.10, shuffle=True, seed=32):
    # Uses seed and shuffling on dataset and produces a train loader, a validation loader and a test loader
    # with defining batch size
    
    # Creating data indices for training and validation splits:
    if kind==1:
         dataset_size = len(dataset)
    else:
        dataset_size = 1293
    indices = list(range(dataset_size))
    val_split = int(np.floor(val_size * dataset_size))
    test_split = int(np.floor(test_size * dataset_size))
    
    if shuffle:
        np.random.seed(seed)  
        np.random.shuffle(indices)  # kanw shuffle exontas arxikopoisei to seed, settarismeno sto debug prokeimenou na exw idio apotelesma
        # indices px [1,4,0,2,5 ...]
    
    train_indices = indices[test_split+val_split:]
    val_indices = indices[:val_split]
    test_indices = indices[val_split:test_split+val_split]

    # Creating PT data samplers and loaders:
    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)
    test_sampler = SubsetRandomSampler(test_indices)

    train_loader = DataLoader(dataset,
                              batch_size=batch_train,
                              sampler=train_sampler)
    val_loader = DataLoader(dataset,
                            batch_size=batch_eval,
                            sampler=val_sampler)
    test_loader = DataLoader(dataset,
                            batch_size=1,
                            sampler=test_sampler)
    
    return train_loader, val_loader, test_loader


def read_multi(spectrogram_file):
    '''
        spectrogram_file:  String, path file
    '''
    spectrogram = np.load(spectrogram_file)[0:128]
    return spectrogram.T


class LabelTransformer(LabelEncoder):
    def inverse(self, y):
        try:
            return super(LabelTransformer, self).inverse_transform(y)
        except:
            return super(LabelTransformer, self).inverse_transform([y])

    def transform(self, y):
        try:
            return super(LabelTransformer, self).transform(y)
        except:
            return super(LabelTransformer, self).transform([y])


# TODO: Comment on why padding is needed
class PaddingTransform(object):
    # Padding when needed
    def __init__(self, max_length, padding_value=0):
        self.max_length = max_length
        self.padding_value = padding_value

    def __call__(self, s):
        '''
            s: numpy array
        '''
        if len(s) == self.max_length:
            return s

        if len(s) > self.max_length:
            return s[:self.max_length] 

        if len(s) < self.max_length:
            # Padding in order to have same numpy shapes for all samples
            # since their timesteps dimension differs 
            s1 = copy.deepcopy(s)
            pad = np.zeros((self.max_length - s.shape[0], s.shape[1]), dtype=np.float32)
            s1 = np.vstack((s1, pad))
            return s1

class SpectrogramDataset(Dataset):
    
    def __init__(self, path, class_mapping=None, train=True, max_length=-1, read_spec_fn=read_multi, kind=-1):
        '''
            path:            String, the filepath of our data
            class_mapping:   Dict, the mapping of kinds of music
            train:           Boolean, (training or testing)
            max_length:      int
            read_spec_fn     function, the way that we would like to use the data
            kind:            int, 0: valence, 1: energy, 2: danceability
        '''
        
        t = 'train' if train else 'test'
        p = os.path.join(path, t)
        self.index = os.path.join(path, "{}_labels.txt".format(t))
        self.files, labels = self.get_files_multi_labels(self.index)
        self.feats = [read_spec_fn(os.path.join(p, f)) for f in self.files]
        self.feat_dim = self.feats[0].shape[1]
        self.lengths = [len(i) for i in self.feats]
        self.max_length = max(self.lengths) if max_length <= 0 else max_length
        self.zero_pad_and_stack = PaddingTransform(self.max_length)
        self.label_transformer = LabelTransformer()
        if isinstance(labels, (list, tuple)):
            self.labels = np.array(labels)

            
    def get_files_multi_labels(self, txt):
        # Returns a list of file names and a list of their labels
        with open(txt, 'r') as fd:
            lines = [l.rstrip().split(',') for l in fd.readlines()[1:]]
            
        files, labels = [], []
        for l in lines:
            label = (float(l[1]),float(l[2]),float(l[3]))
            labels.append(label)
            # Kaggle automatically unzips the npy.gz format so this hack is needed
            _id = int(l[0])
            npy_file = '{}.fused.full.npy'.format(_id)
            files.append(npy_file)
            
        return files, labels

def __getitem__(self, item):
        # Returns padded item, item label, l
        return self.zero_pad_and_stack(self.feats[item]), self.labels[item]

def __len__(self):
        # Returns the number of dataset samples
        return len(self.labels)



import torch
import pickle
from torch.utils.data import Dataset
import torch.nn as nn
import warnings
warnings.filterwarnings("ignore")
import torch.nn.functional as F
from torch.autograd import Variable
import matplotlib.pyplot as plt
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
from sklearn.metrics import classification_report

class CNN(nn.Module):

    def __init__(self):
    
        super(CNN, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 4, kernel_size=3),
            nn.BatchNorm2d(4),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )    
        self.layer2 = nn.Sequential(
            nn.Conv2d(4, 32, kernel_size=5),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)    
            )
        self.layer3 = nn.Sequential(
            nn.Conv2d(32, 64, kernel_size=5),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )
        self.layer4 = nn.Sequential(
            nn.Conv2d(64,128, kernel_size=3),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
            
        )
        
        self.fc1 = nn.Linear(49920, 10)
        
        
        
        
    def forward(self, x):
        # Forward function of CNN
        
        out = self.layer1(x)     # conv1
        out = self.layer2(out)   # conv2
        out = self.layer3(out)   # conv3
        out = self.layer4(out)   # conv4
        out = out.view(out.size(0), -1)
        out = self.fc1(out)      # fully-connected1
        return out
    
def training_CNN(trainloader,valloader,model_name,input_size,dataset,obover):
    if obover==True:
        maxseqlen = dataset.max_length
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    #defining mnodel and the hyperparameters
        train_loss=[]
        num_classes=10
        num_epochs=200
        maxseqlen=trainloader.dataset.max_length

        model = CNN().to(device)
        model = model.double()


        # Loss and optimizer
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)

        #take only 1 batch & transfer it to GPU
        feats, labels, lengths= next(iter(trainloader))
        feats=feats.reshape(-1,1,maxseqlen,input_size)
        feats, lengths, labels= feats.to(device),lengths.to(device),labels.to(device)

        for epoch in range(num_epochs):

            # Forward pass
            outputs = model.forward(feats)
            loss = criterion(outputs, labels)

            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss.append(round(loss.item(),4))

            #print results
            print('Epoch [{}/{}], Training Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))



        # Plotting learning curve
        running_loss=np.array(train_loss)
        plt.figure()
        plt.plot(running_loss, label="training loss")
        plt.xlabel('epoch')
        plt.ylabel('mean loss in the epoch')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
        plt.show()




    elif obover==False:  
        model_name+= ".sav"

        #defining the device
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
      
        #defining the hyperparameters and the  model
        maxseqlen = -1
        num_classes = 10
        num_epochs = 30
        learning_rate = 0.001


        maxseqlen = dataset.max_length
        model = CNN().to(device)
        model = model.double()
        

        #loss_criterion and optimizer
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        ts = len(trainloader)

        v_loss=[]
        t_loss=[]
        train_loss=[]

        for epoch in range(num_epochs):# loop over the dataset multiple times 
            with torch.no_grad():

                val_loss = 0.0
                best_val_loss = 1000000000
                total=0
                correct=0
                for i, (feats,labels,lengths) in enumerate(valloader):

                    feats_val = feats.reshape(-1,1, maxseqlen, input_size).to(device)
                    labels = labels.to(device) 
                    labels = torch.tensor(labels, dtype=torch.long, device=device)
                    lengths = lengths.to(device) 

                    # forward + validation_loss
                    outputs = model.forward(feats_val)
                    criterion = nn.CrossEntropyLoss()
                    loss = criterion(outputs, labels)
                    val_loss+= loss.item()

                    #checking the performance of the validation set at the end of each epoch
                    _, predicted = torch.max(outputs.data, -1)
                    total += labels.size(0)
                    correct += (predicted == labels).sum().item()
                if epoch>=1:
                    print('Validation Accuracy after the end of the nu'+str(epoch)+' epoch= {} %'.format(100 * correct / total))

            v_loss.append(val_loss/len(valloader))

            if val_loss<=best_val_loss:
                best_val_loss = val_loss
                pickle.dump(model, open(model_name, 'wb'))
                torch.save(model.state_dict(),"w8s.pt")


            running_loss=0.0
            train_loss.append([])
            for i,(feats, labels, lengths) in enumerate(trainloader):
                feats = feats.reshape(-1, 1,maxseqlen, input_size).to(device)
                labels = labels.to(device)
                labels = torch.tensor(labels, dtype=torch.long, device=device)
                lengths = lengths.to(device)

                #Forward_pass,Backward,Optimize
                outputs = model.forward(feats)
                loss = criterion(outputs, labels)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                if (i) % 8 == 0:
                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                           .format(epoch+1, num_epochs, i+1, ts, loss.item()))
                train_loss[epoch].append(loss.item())

                # epoch loss
                running_loss += loss
                running_loss = running_loss / len(trainloader)

            t_loss.append(np.mean(train_loss))


        # Tranform losses to numpy arrays
        t_loss=np.array(t_loss)
        v_loss=np.array(v_loss)

        # Plotting learning curve
        plt.figure()
        plt.plot(t_loss, label="training loss")
        plt.plot(v_loss, label="validation loss")
        plt.xlabel('epoch')
        plt.ylabel('mean loss in the epoch')
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
        plt.show()
    
    return maxseqlen
            
            
            
            
            




def score_CNN(test_loader,input_size,model_name, maxseqlen):
    # Estimating the model with classification report
    model_name += ".sav"
    loaded_model = pickle.load(open(model_name, 'rb'))
    maxseqlen=test_loader.dataset.max_length
    
    # Disable batch normalization and dropout in testing
    loaded_model.eval()
    
    with torch.no_grad():
        correct = 0
        total = 0
        y_pred = []
        y_true = []
        for i,(feats, labels, lengths) in enumerate(test_loader):
            feats_test = feats.reshape(-1,1, maxseqlen, input_size).to(device)
            labels = labels.to(device)
            labels = torch.tensor(labels, dtype=torch.long, device=device)
            lengths = lengths.to(device)
            outputs2 = loaded_model.forward(feats_test)
            _, predicted = torch.max(outputs2.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            for pred in predicted:
                   y_pred.append(pred.item())
            for label in labels:
                  y_true.append(label.item())
    print(classification_report(y_true, y_pred))

maxseqlen = training_CNN(train_loader_mel, val_loader_mel, model_name="cnn_single_mel2", input_size=128, dataset=mel_specs,obover=False)
multi_set = SpectrogramDataset('../input/patreco3-multitask-affective-music/data/multitask_dataset/', train=True,
                                    class_mapping=None, max_length=-1,
                                    read_spec_fn=read_multi)
# Train and Test loaders

print(multi_set.max_length)

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable

from torch.optim import lr_scheduler
def train_CNN(train_loader, val_loader, val_name, mels, dataset):
    '''
        train_loader:  Dataloader
        val_loader:    Dataloader
        val_name:      String
        mels:          int, input size
        dataset:       SpectrumDataset
    '''
    
    val_name += ".pkl"
    
    # Device configuration
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Hyper-parameters
    num_epochs = 350
    learning_rate = 0.0001
    lambda1 = 0.00002
    
    maxseqlen = dataset.max_length

    model = CNN().to(device)
    model = model.double()

    # Loss and optimizer
    criterion = nn.MSELoss() 
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    
    # Train the model
    train_loss = []
    vl = []
    tl = []
    best_val_loss = np.Inf
    total_step = len(train_loader)
    for epoch in range(num_epochs):
        train_loss.append([])
        val_loss = 0

        count = 0
        model.eval()
        with torch.no_grad():
            for i, (feats, labels) in enumerate(val_loader):
                # Validation set
                feats = feats.view(-1, 1, maxseqlen, mels).to(device)
                labels = labels.to(device).double()
#                 print(labels)
                # Forward pass
                outputs = model.forward(feats)
                MSE_loss = criterion(outputs, labels)
                fc1_params = torch.cat([x.view(-1) for x in model.fc1.parameters()])
                l1_regularization = lambda1 * torch.norm(fc1_params, 1)
                loss = MSE_loss + l1_regularization
                val_loss += loss.item()
                count += 1

            vl.append(val_loss / count)

            if val_loss <= best_val_loss and epoch > 3:
                print("changed val")
                # Keep the model with minimum validation loss
                best_val_loss = val_loss
                joblib_file = val_name  
                torch.save(model, joblib_file)

        model.train()
        for i, (feats, labels) in enumerate(train_loader):
            
            # Training set
            feats_reshape = feats.view(-1, 1, maxseqlen, mels).to(device)
            labels = labels.to(device).double()

            # Forward pass
            outputs = model.forward(feats_reshape)
            MSE_loss = criterion(outputs, labels)
            fc1_params = torch.cat([x.view(-1) for x in model.fc1.parameters()])
            l1_regularization = lambda1 * torch.norm(fc1_params, 1)
            loss = MSE_loss + l1_regularization
            
            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_loss[epoch].append(loss.item())
            
        print("epoch: " + str(epoch+1), "\nTrain loss:\t\t", np.mean(train_loss[epoch]))
        for param_group in optimizer.param_groups:
            print("LR", param_group['lr'])
        print("Validation loss:\t", val_loss / count)
        print()
        
        tl.append(np.mean(train_loss[epoch]))

    tl=np.array(tl)
    vl=np.array(vl)

    
    # Plotting learning curve
    plt.figure()
    plt.plot(tl[2:], label="training loss")
    plt.plot(vl[2:], label="validation loss")
    plt.xlabel('epoch')
    plt.ylabel('mean loss in the epoch')
    plt.title('multitask learning curve')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
    plt.show()
    return maxseqlen
    
            
import warnings
warnings.simplefilter("ignore", UserWarning)

train_loader_multi, val_loader_multi, test_loader_multi = torch_train_val_test_split(multi_set, batch_train=32, batch_eval=32, val_size=.15, test_size=.15,kind=0)

maxseqlen = train_CNN(train_loader_multi, val_loader_multi, "cnn_multi0", mels=128, dataset=multi_set)
scores=score_CNN(test_loader_multi, "cnn_multi0", mels=128, maxseqlen=maxseqlen)